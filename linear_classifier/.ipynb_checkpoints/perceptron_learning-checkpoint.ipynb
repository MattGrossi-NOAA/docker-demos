{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to adjust weights\n",
    "def adjust_weights(weights, att, tar, hyp, eta):\n",
    "    \"\"\"\n",
    "    Returns adjusted weight(s) based on the learning rate, corresponding\n",
    "    attribute value(s), and the difference between the known and hypothesized\n",
    "    class.\n",
    "    \n",
    "    Inputs:\n",
    "        weights: weight(s) to be adjusted\n",
    "        att: corresponding attribute(s)\n",
    "        tar: known class (from data; i.e., the 'target')\n",
    "        hyp: hypothesized class (from classifier)\n",
    "        eta: learning rate\n",
    "    Outputs:\n",
    "        aw: adjusted weight(s)\n",
    "    \"\"\"\n",
    "    return weights + (eta * (tar - hyp) * att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(weights, examples):\n",
    "    \"\"\"\n",
    "    Run linear classifier that returns 1 if the weighted sum is greater than\n",
    "    zero or 0 otherwise.\n",
    "    \n",
    "    Inputs:\n",
    "        weights: array of weight(s) making up the linear classifier\n",
    "        examples: 2D array of examples to classify, one example per row\n",
    "    \"\"\"\n",
    "    ws = np.sum(weights * examples, axis=1)\n",
    "    h = ws > 0\n",
    "    return h.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(weights, examples):\n",
    "    \"\"\"\n",
    "    Return the fraction of examples whose class was correctly identified.\n",
    "    \n",
    "    Inputs:\n",
    "        weights: array of weight(s) making up the linear classifier\n",
    "        examples: 2D array of examples to classify, one example per row\n",
    "    \"\"\"\n",
    "    h = run_model(weights=weights, examples=examples[:,0:-1])\n",
    "    num_correct = np.sum(examples[:,-1] == h)\n",
    "    return num_correct / len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = np.loadtxt(fname='banknote.csv', delimiter=',')\n",
    "\n",
    "# Normalize\n",
    "MAX = data.max(axis=0)\n",
    "MIN = data.min(axis=0)\n",
    "norm = (data - MIN) / (MAX - MIN)\n",
    "\n",
    "# Append artificial \"zeroth\" attribute x0=1\n",
    "# (i.e., \"bias\", used for weight-training)\n",
    "norm = np.append(arr=np.ones([len(norm),1]), values=norm, axis=1)\n",
    "\n",
    "# Shuffle examples\n",
    "np.random.shuffle(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training fraction \n",
    "train = 0.75\n",
    "\n",
    "# Training/testing subsets\n",
    "trainInd = round(train * len(norm))\n",
    "trainSS = norm[:trainInd]\n",
    "testSS = norm[trainInd:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate\n",
    "eta = 0.3\n",
    "\n",
    "# Training Threshold (stop when obtained)\n",
    "threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "weights = np.random.random(5)\n",
    "weights_archive = weights[:]\n",
    "\n",
    "# Epoch counter\n",
    "num_epoch = 0\n",
    "\n",
    "# Record percent error as each training example is presented\n",
    "pct_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Percent Error 55.3936%\n",
      "Epoch 2: Percent Error 8.1633%\n",
      "\n",
      "Final accuracy on train data: 91.84%\n",
      "Accuracy on test data: 90.67%\n"
     ]
    }
   ],
   "source": [
    "# Initial model\n",
    "trainAcc = accuracy(weights=weights, examples=trainSS) * 100\n",
    "pct_error.append(100 - np.round(trainAcc, 4))\n",
    "\n",
    "# Train\n",
    "while trainAcc < threshold*100:\n",
    "    print(f'Epoch {num_epoch}: Percent Error {np.round(100-trainAcc, 4)}%')\n",
    "\n",
    "    # Update epoch counter\n",
    "    num_epoch += 1\n",
    "    \n",
    "    # Loop through each training example\n",
    "    for ex in trainSS:\n",
    "        # Attributes and class label\n",
    "        attributes = ex[0:-1].reshape(1,-1)\n",
    "        classLabel = ex[-1]\n",
    "\n",
    "        # Model hypothesis\n",
    "        hypothesis = run_model(weights=weights,\n",
    "                               examples=attributes)\n",
    "\n",
    "        # Adjust and record weights\n",
    "        weights = adjust_weights(weights=weights,\n",
    "                                 att=attributes,\n",
    "                                 tar=classLabel,\n",
    "                                 hyp=hypothesis,\n",
    "                                 eta=eta)\n",
    "        weights_archive = np.row_stack((weights_archive, weights))\n",
    "\n",
    "    # Accuracy\n",
    "    trainAcc = accuracy(weights=weights, examples=trainSS) * 100\n",
    "    pct_error.append(100-np.round(trainAcc, 4))\n",
    "\n",
    "print(f'Epoch {num_epoch}: Percent Error {np.round(100-trainAcc, 4)}%\\n')\n",
    "    \n",
    "# Final status\n",
    "testAcc = accuracy(weights=weights, examples=testSS)*100\n",
    "print(f'Final accuracy on train data: {np.round(trainAcc, 2)}%')\n",
    "print(f'Accuracy on test data: {np.round(testAcc, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    \"\"\"\n",
    "    Embarrassingly simple linear classifier using perceptron learning.\n",
    "    \n",
    "    Initialization inputs:\n",
    "        data: str, fileneame of CSV data to be trained on, organized with row-wise \n",
    "            examples and column-wise attributes. Known classes are expected to be in \n",
    "            the last column.\n",
    "        train: float, 0 < train < 1, specifies the fraction of data to be used for\n",
    "            training. Defaults to 0.75.\n",
    "        threshold: float, 0 < threshold < 1, the accuracy threshold above which the \n",
    "            model is considered adequate and training stops. Defaults to 0.9.\n",
    "        lr: float, learning rate used to adjust weights during training. Usually <1. \n",
    "            Defaults to 0.1\n",
    "        seed: int, used to set random seed prior to weight initialization for \n",
    "            reproducibility. If not supplied, weights will be initialized \n",
    "            differently for every instantiation (default).\n",
    "        verbose: Boolean controlling whether model performance status should be \n",
    "            printed during training.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, train=0.75, threshold=0.9, lr=0.1, seed=None,\n",
    "                 verbose=True):\n",
    "        self.dfile = data\n",
    "        self.training = train\n",
    "        self.threshold = threshold * 100\n",
    "        self.eta = lr\n",
    "        self.seed = seed\n",
    "        self.verbose = verbose\n",
    "    \n",
    "        # Load data\n",
    "        self.data = np.loadtxt(fname=self.dfile, delimiter=',')\n",
    "\n",
    "        # Normalize\n",
    "        MAX = self.data.max(axis=0)\n",
    "        MIN = self.data.min(axis=0)\n",
    "        self.norm = (self.data - MIN) / (MAX - MIN)\n",
    "        \n",
    "        # Append artificial \"zeroth\" bias attribute x0=1\n",
    "        # (used for weight-training)\n",
    "        self.norm = np.append(arr=np.ones([len(self.norm),1]),\n",
    "                              values=self.norm, axis=1)\n",
    "        \n",
    "        # Initialize\n",
    "        self.initialize(shuffle=True)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'Embarrassingly simple linear classifier using perceptron learning.'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Embarrassingly simple linear classifier trained on {self.dfile}'\n",
    "\n",
    "    def initialize(self, shuffle=True):\n",
    "        \"\"\"\n",
    "        Randomly initialize weights.\n",
    "        \n",
    "        Input:\n",
    "            shuffle: Boolean whether normalized data should be shuffled first. If \n",
    "                True (default), the newly shuffled data are also subset according to \n",
    "                'train' argument passed at instance initialization or as set by\n",
    "                set_train_subset method.\n",
    "        \"\"\"\n",
    "        # Shuffle examples\n",
    "        if shuffle:\n",
    "            self.shuffled = self.norm[:]\n",
    "            np.random.shuffle(self.shuffled)\n",
    "\n",
    "            # Training/testing subsets\n",
    "            trainInd = round(self.training * len(self.shuffled))\n",
    "            self.trainSS = self.shuffled[:trainInd]\n",
    "            self.testSS = self.shuffled[trainInd:]        \n",
    "    \n",
    "        # Initialize weights\n",
    "        wgts_rng = np.random.default_rng(seed=self.seed)\n",
    "        self.weights = wgts_rng.random(5)\n",
    "        \n",
    "    def reset(self, shuffle=True, seed=None):\n",
    "        \"\"\"\n",
    "        Re-initialize model to random weights for retraining.\n",
    "        \n",
    "        Input:\n",
    "            shuffle: Boolean whether normalized data should be shuffled first. If \n",
    "                True (default), the newly shuffled data are also subset according to \n",
    "                'train' argument passed at instance initialization or as set by\n",
    "                set_train_subset method.\n",
    "            seed: int, optionally set random seed prior to weight initialization. \n",
    "                Set this for reproducibility. If not supplied, weights will be \n",
    "                initialized differently every time.\n",
    "        \"\"\"\n",
    "        if seed:\n",
    "            if isinstance(seed, int):\n",
    "                self.seed = seed\n",
    "            elif isinstance(seed, str) and seed.lower() == 'none':\n",
    "                self.seed = None\n",
    "            else:\n",
    "                raise ValueError(\"'seed' must be either an int or string \"\\\n",
    "                                 \"string 'None' to set to NoneValue\")\n",
    "            warnings.warn('Random seed has been set and may be different than what was used to initiate this Linear instance.')\n",
    "        self.initialize(shuffle=shuffle)\n",
    "    \n",
    "    def adjust_weights(self, att, tar, hyp):\n",
    "        \"\"\"\n",
    "        Adjust weight(s) based on the learning rate, attribute values, and the\n",
    "        difference between the known and hypothesized classes.\n",
    "\n",
    "        Inputs:\n",
    "            att: example attribute(s)\n",
    "            tar: known class (from data; i.e., the 'target')\n",
    "            hyp: hypothesized class (from classifier)\n",
    "        \"\"\"\n",
    "        self.weights = self.weights + (self.eta * (tar - hyp) * att)\n",
    "    \n",
    "    def set_train_subset(self, fraction):\n",
    "        \"\"\"\n",
    "        Set the fraction of data to be used for training.\n",
    "        \n",
    "        Input:\n",
    "            fraction: float, 0 < fraction < 1\n",
    "        \"\"\"\n",
    "        self.training = fraction\n",
    "    \n",
    "    def set_threshold(self, threshold):\n",
    "        \"\"\"\n",
    "        Set the accuracy threshold above which the model is considered trained.\n",
    "        \n",
    "        Input:\n",
    "            threshold: float, 0 < threshold < 1\n",
    "        \"\"\"\n",
    "        self.thresh = threshold * 100\n",
    "    \n",
    "    def set_lr(self, lr):\n",
    "        \"\"\"\n",
    "        Set learning rate used for training.\n",
    "        \n",
    "        Input:\n",
    "            lr: float, usually <1\n",
    "        \"\"\"\n",
    "        self.eta = lr\n",
    "\n",
    "    def set_verbose(self, verbose):\n",
    "        \"\"\"\n",
    "        Set whether model performance status should be printed during training.\n",
    "        \n",
    "        Input:\n",
    "            verbose: Boolean\n",
    "        \"\"\"\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def run_model(self, weights, examples):\n",
    "        \"\"\"\n",
    "        Run linear classifier that returns 1 if the weighted sum is greater than\n",
    "        zero or 0 otherwise.\n",
    "\n",
    "        Inputs:\n",
    "            weights: array of weight(s) making up the linear classifier\n",
    "            examples: 2D array of examples to classify, one example per row\n",
    "        \"\"\"\n",
    "        ws = np.sum(weights * examples, axis=1)\n",
    "        h = ws > 0\n",
    "        return h.astype(int)\n",
    "\n",
    "    def get_weights(self):\n",
    "        \"\"\"Return existing model weights (parameters).\"\"\"\n",
    "        return self.weights\n",
    "    \n",
    "    def accuracy(self, weights, examples):\n",
    "        \"\"\"\n",
    "        Return the fraction of examples whose class was correctly identified.\n",
    "\n",
    "        Inputs:\n",
    "            weights: array of weight(s) making up the linear classifier\n",
    "            examples: 2D array of examples to classify, one example per row\n",
    "        \"\"\"\n",
    "        h = self.run_model(weights=weights, examples=examples[:,0:-1])\n",
    "        num_correct = np.sum(examples[:,-1] == h)\n",
    "        return np.round(((num_correct / len(examples)) * 100), 3)\n",
    "\n",
    "    def error(self, weights, examples):\n",
    "        \"\"\"\n",
    "        Return the fraction of examples whose class was incorrectly identified.\n",
    "\n",
    "        Inputs:\n",
    "            weights: array of weight(s) making up the linear classifier\n",
    "            examples: 2D array of examples to classify, one example per row\n",
    "        \"\"\"\n",
    "        h = self.run_model(weights=weights, examples=examples[:,0:-1])\n",
    "        num_incorrect = np.sum(examples[:,-1] != h)\n",
    "        return np.round(((num_incorrect / len(examples)) * 100), 3)\n",
    "\n",
    "    def test(self, traindata=False):\n",
    "        \"\"\"\n",
    "        Test the current model. Returns tuple (accuracy, error) as percentages of\n",
    "        examples classified correctly and incorrectly, respectively.\n",
    "        \n",
    "        Input:\n",
    "            traindata: Boolean indicating whether accuracy and error should be\n",
    "                calculated on training subset. Defaults to False (testing subset)\n",
    "        \"\"\"\n",
    "        ds = self.trainSS if traindata else self.testSS\n",
    "        acc = self.accuracy(weights=self.weights, examples=ds)\n",
    "        err = self.error(weights=self.weights, examples=ds)\n",
    "        return (acc, err)\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        self.num_epoch = 0\n",
    "        \n",
    "        # Test initial model\n",
    "        self.trainAcc, self.trainErr = self.test(traindata=True)\n",
    "        \n",
    "        # Train\n",
    "        while self.trainAcc < self.threshold:\n",
    "            if self.verbose:\n",
    "                print(f'Epoch {self.num_epoch}: Percent Error {self.trainErr}%')\n",
    "\n",
    "            # Update epoch counter\n",
    "            self.num_epoch += 1\n",
    "\n",
    "            # Loop through each training example\n",
    "            for ex in self.trainSS:\n",
    "                attributes = ex[0:-1].reshape(1,-1)\n",
    "                classLabel = ex[-1]\n",
    "                hypothesis = self.run_model(weights=self.weights, \n",
    "                                            examples=attributes)\n",
    "                self.adjust_weights(att=attributes, tar=classLabel, hyp=hypothesis)\n",
    "                \n",
    "            # Test current model\n",
    "            self.trainAcc, self.trainErr = self.test(traindata=True)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f'Epoch {self.num_epoch}: Percent Error {self.trainErr}%\\n')\n",
    "\n",
    "        # Final status\n",
    "        self.testAcc, self.testErr = self.test(traindata=False)\n",
    "        print(f'Final accuracy on training data: {self.trainAcc}%')\n",
    "        print(f'Accuracy on testing data: {self.testAcc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51182162, 0.9504637 , 0.14415961, 0.94864945, 0.31183145])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Linear(data='banknote.csv', train=0.75, threshold=0.9, lr=0.01,\n",
    "               verbose=True, seed=1)\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Percent Error 55.102%\n",
      "Epoch 1: Percent Error 48.785%\n",
      "Epoch 2: Percent Error 17.298%\n",
      "Epoch 3: Percent Error 12.245%\n",
      "Epoch 4: Percent Error 1.749%\n",
      "\n",
      "Final accuracy on training data: 98.251%\n",
      "Accuracy on testing data: 97.376%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.13182162, -0.107347  , -0.10065039, -0.09462214,  0.00733456]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51182162, 0.9504637 , 0.14415961, 0.94864945, 0.31183145])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reset(shuffle=False)\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Percent Error 55.102%\n",
      "Epoch 1: Percent Error 48.785%\n",
      "Epoch 2: Percent Error 17.298%\n",
      "Epoch 3: Percent Error 12.245%\n",
      "Epoch 4: Percent Error 1.749%\n",
      "\n",
      "Final accuracy on training data: 98.251%\n",
      "Accuracy on testing data: 97.376%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.13182162, -0.107347  , -0.10065039, -0.09462214,  0.00733456]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51182162, 0.9504637 , 0.14415961, 0.94864945, 0.31183145])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reset(shuffle=True)\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Percent Error 55.588%\n",
      "Epoch 1: Percent Error 45.773%\n",
      "Epoch 2: Percent Error 18.562%\n",
      "Epoch 3: Percent Error 3.207%\n",
      "\n",
      "Final accuracy on training data: 96.793%\n",
      "Accuracy on testing data: 97.668%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.13182162, -0.1113166 , -0.084855  , -0.08318149, -0.00177857]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47836/2500849452.py:97: UserWarning: Random seed has been set and may be different than what was used to initiate this Linear instance.\n",
      "  warnings.warn('Random seed has been set and may be different than what was used to initiate this Linear instance.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.80901901, 0.77788219, 0.57288856, 0.59766846, 0.91894066])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reset(shuffle=False, seed='None')\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Percent Error 55.588%\n",
      "Epoch 1: Percent Error 44.218%\n",
      "Epoch 2: Percent Error 16.618%\n",
      "Epoch 3: Percent Error 5.053%\n",
      "\n",
      "Final accuracy on training data: 94.947%\n",
      "Accuracy on testing data: 93.294%\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13586051, 0.48824849, 0.8291498 , 0.91344898, 0.02719304])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reset(shuffle=False)\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
